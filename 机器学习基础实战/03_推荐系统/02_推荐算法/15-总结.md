### K近邻协同过滤

用户向量 物品向量相似度计算，MemoryBased CF

之前没有考虑近邻问题，而是利用所有正相关用户

考虑K近邻只需要按照相似度找到相似度最高的N个用户

similar_users = self.similar[uid].drop([uid]).dropna().sort_values(ascending=False)[:self.k]



### Baseline:基准预测

- 所有用户评分平均值

- 找到每一个用户对物品平均评分的bias: bu

- 找到每一个物品平均评分的bias: bi

- 预测的得分 mean+bu+bi u代表第u个用户 i代表第i个物品

- 可以使用梯度下降来优化损失

  

- baseline 的思想来解决协同过滤的问题

  - 计算出所有用户对所有物品评分的平均值
  - 预测的评分=在平均值的基础上+用户的评分偏置+物品的评分偏置
  - 求解所有用户的评分偏置 和 所有物品的得分偏置
  - 这个问题可以转换成损失优化的过程

- 梯度下降

- 交替最小二乘法 (ALS)



### 矩阵分解

- SVD奇异值分解
  - 一个 大矩阵 分成 三个小矩阵， 中间是一个k阶的方阵
  - SVD 只适用于没有缺失，必须是稠密矩阵
- Funk SVD
  - 一个大矩阵，分成两个小矩阵
  - LFM原理
- BiasSVD 矩阵分解 + baseline
- SVD++ 矩阵分解 + baseline + 其他影响（点击、收藏、购买）



### 基于内容的推荐

- 画像的构建
  - 物品画像
    - 分类信息
    - 标题
    - 电影/音乐的 主演、歌手
  - 用户画像
    - 喜好的物品类别 行为偏好
    - 基本的人口学属性 （年龄、性别等）
    - 活跃程度
    - 风控的维度（薅羊毛）
  - **物品和用户的 字段 一般上百来个。**
- 物品标签哪里来？
  - PGC 应用自己生成
  - UGC 用户生成

- 基于内容推荐的算法流程
  - 用户画像/物品画像
  - 匹配用户画像/物品画像
- 物品冷启动问题
  - 画像—>词向量—>物品向量—>计算物品的相似度
  - 从文本描述的角度来找相似的物品
  - 当用户在浏览A的时候，通过上述套路找到与物品A相似的一系列物品



### 基于内容推荐的流程

①建立物品画像

- ①用户给打的tag  ②电影的分类值
- 根据电影的id 把tag和分类值合并起来 求tf-idf
- 根据 if-idf 的结果为每一部电影筛选出 top-n个（if-idf比较大的）关键词
- 建立电影id-关键词-关键词权重的列表

②建立倒排索引

- 通过关键词找到对应的电影
- 遍历 电影id-关键词-关键词权重的列表，读取每一个关键词，用关键词作为key，【关键词对应电影id，tf-idf】作为value保存到dict中

③创建一个用户画像

- 看用户看过哪些电影，到电影的 电影id-关键词-关键词权重 数据中找到电影所对应的关键词。
- 把用户看过的所有关键词放在一起，统计词频 每个词出现几次
- 出现次数多的关键词作为用户的关键词，这个关键词实际上就是用户画像的关键词

④根据用户的兴趣词找到兴趣词对应的电影，多个兴趣词可能对应一个电影 {电影id：[关键词1的权重，关键词2的权重]}

- 把每一部电影对应的关键词权重求和后排序，权重比较高的排在前面，推荐给用户。



### 词向量

- 用向量来表示一个词语，可以表示语义层面的含义
- 如果用word2vec模型创建的词向量，两个词向量相似度比较高，说明这两个词是近义词
- 词向量作用：把含义相近的判断转换成 向量的相似度计算
- 使用 Gensim 的 word2vec训练词向量模型

```python
import gensim
# 准备所有用来训练词向量模型的文本内容
sentences = list(movie_profile["profile"].values)

# 参数1 文本 参数2 window 观察上下文关系的窗口长度
# min_count 训练模型时要保留下来的词语出现的频率 iter 迭代次数
model = gensim.models.Word2Vec(sentences, window=3, min_count=1, iter=20)
```

- 通过词向量模型找到top-N的相似词

```python
model.wv.most_similar(positive=["要找相似的词对的词"], topn=10)
```

- 训练文档向量 Doc2vec

```python
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
documents = [TaggedDocument(words, [movie_id]) for movie_id, words in movie_profile["profile"].iteritems()]
# 训练模型并保存 Doc2vec 通过向量来表示一篇文档 一篇文档对应一个电影
# 向量的相似度 代表了电影的相似度
model = Doc2Vec(documents, vector_size=100, window=3, min_count=1, workers=4, epochs=20)
words = movie_profile["profile"].loc[6]
# 导入电影的标签，找到电影文档对应的向量
inferred_vector = model.infer_vector(words)
# 通过Doc2vec 找到传入的向量相似的n个向量，每一个向量代表了一个电影
sims = model.docvecs.most_similar([inferred_vector], topn=10)
```

