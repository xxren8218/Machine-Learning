### K近邻协同过滤

用户向量 物品向量相似度计算，MemoryBased CF

之前没有考虑近邻问题，而是利用所有正相关用户

考虑K近邻只需要按照相似度找到相似度最高的N个用户

similar_users = self.similar[uid].drop([uid]).dropna().sort_values(ascending=False)[:self.k]



### Baseline:基准预测

- 所有用户评分平均值

- 找到每一个用户对物品平均评分的bias: bu

- 找到每一个物品平均评分的bias: bi

- 预测的得分 mean+bu+bi u代表第u个用户 i代表第i个物品

- 可以使用梯度下降来优化损失

  

- baseline 的思想来解决协同过滤的问题
  - 计算出所有用户对所有物品评分的平均值
  - 预测的评分=在平均值的基础上+用户的评分偏置+物品的评分偏置
  - 求解所有用户的评分偏置 和 所有物品的得分偏置
  - 这个问题可以转换成损失优化的过程

- 梯度下降
- 交替最小二乘法 (ALS)



### 矩阵分解

- SVD奇异值分解
  - 一个 大矩阵 分成 三个小矩阵， 中间是一个k阶的方阵
  - SVD 只适用于没有缺失，必须是稠密矩阵
- Funk SVD
  - 一个大矩阵，分成两个小矩阵
  - LFM原理
- BiasSVD 矩阵分解 + baseline
- SVD++ 矩阵分解 + baseline + 其他影响（点击、收藏、购买）
- 

