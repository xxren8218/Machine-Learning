- Hive Hadoop

- Hive 和传统关系型数据库区别

### Spark 概念

- 基于内存的分布式计算框架
- 只负责算 不负责存
- spark 在离线计算 功能上 类似于mapreduce的作用
- MapReduce的缺点
  - 运行速度慢 （没有充分利用内存）
  - 接口比较简单，仅支持Map Reduce
  - 功能比较单一 只能做离线计算

- Spark优势
  - 运行速度快
  - 自身生态比较完整
    - spark sql
    - spark streaming
    - spark mllib Spark ML
  - api 比较丰富
  - 使用各种语言进行操作

### RDD 的概念

- 弹性分布式数据集
- spark当中对数据的抽象
- 所有spark中对数据的操作最终都会转换成RDD的操作
  - spark sql
  - spark streaming 实时计算
  - spark ML 、spark mllib  机器学习
- RDD 分布式的 可容错 可以进行并行计算

- rdd 的存储可以对比HDFS
  - hdfs 数据拆分成多个block  rdd 拆分成多个partition
  - 读取的时候 spark 加载hdfs数据 1个block 对应 spark rdd的一个partition
  - 写数据的时候 spark 1个partition 可能对应多个block
- RDD是不可变的
  - 父RDD 生成一个子 RDD 父RDD的状态不会变化
  - 从容错的角度去做这样的设计

### RDD的创建

- 创建RDD之前先要有Spark Context

  ```python
  conf = SparkConf().setAppName(appName).setMaster(master)
  sc = SparkContext(conf=conf)
  ```

- 通过内存中的数据创建RDD
  - data = [1, 2, 3, 4, 5]
    distData = sc.parallelize(data)
- 创建RDD时可以指定 partition的数量（RDD会分成几份）一个partition会对应一个task，根据CPU的内核数来指定partition (1核对应2~4个partition)
- 从文件创建RDD 可以是HDFS支持的任何一种存储介质
  - 可以从 hdfs、  数据库(mysql)  、本地文件系统 、hbase、 这些地方加载数据创建RDD
  - rdd = sc.textFile('file:///root/tmp/test.txt')

### RDD的三类算子

- transformation
  - 所有的transformation 都是延迟执行的，只要不调用action 不会执行，只是记录过程
  - transformation 这一类算子返回值还是 rdd
  - rdd.transformation 还会得到新的rdd
- action
  - 会触发之前的rdd所有的transformation
  - 获取最终的结果
- persist——持久化操作
  - 数据存储，可以存到内存，也可以是磁盘

### 通过pycharm 链接centos环境

![1555730758534](1555730758534.png)

![1555730849262](1555730849262.png)

![1555730962360](1555730962360.png)

### ip地址统计案例

- 广播变量

  - 如果多个task会用到同一份数据，默认每个task都会复制一份

  - 用到的数据如果只是查询可以通过广播变量保存，避免数据的反复复制

  - SparkContext可以创建广播变量

    ```python
    广播变量= sc.broadcast(值)
    # 使用
    广播变量。value
    ```

- mapPartitions 

  - transformation操作 
  - 类似map 但是map是一条一条传给里面函数的 mapPartitions 数据是一部分一部分传给函数的
  - 应用场景 数据处理的时候 需要连接其它资源 如果一条一条处理 会处理一条连一次， 一份一份处理可以很多条数据连一次其它资源 可以提高效率

- 二分法查找

- ip_transform 把223.243.0.0 转换成10进制的数字

### spark standalone模式

- Master （ResourceManager）

  - 主节点
  - 负责Worker状态管理
  - 响应client 提交来的Application

- Worker （NodeManager）

  - 管理自身资源
  - 运行Application对应的task
  - 启动driver 执行application

- Executor（Counitiner）

  - task 最终执行的容器

- Application（运行的作业）

  - spark作业

- Driver（ApplicationManager）

  - 作业提交给spark的时候 先由一个Worker启动一个Driver来分析Application
  - DAGScheduler
    - task划分 交给TaskScheduler
    - 作业可以划分为多个stage
    - 每一个stage根据partition的数量决定由多少个task
  - TaskScheduler
    - 将task调度到对应的Executor上执行

- Client

  

### spark core总结

- spark core是 spark生态最核心的部分
- spark 生态
  - spark core  类比mapreduce
  - spark sql （翻译成RDD进行计算） 类比hive（翻译成SQL进行MR）
  - spark streaming   storm、flink
  - spark ML 基于dataframe （机器学习库）
  - sparkmllib 基于 rdd （机器学习库）
- spark
  - 基于【内存】的 【分布式】【计算】框架
- MapReduce 和 spark 优劣
  - spark 基于内存 算快
  - spark api 更丰富 比mapreduce 代码少
  - spark 生态完整 
    - 离线计算   spark core & spark sql
    - 实时计算/流式计算 spark streaming **准实时**(定义时间间隔，如1S处理一次) 
    - 交互式计算 spark sql dataframe
    - 机器学习 spark ML
- RDD（Spark core最核心部分）
  - 弹性分布式数据集
  - 不可变 rdd->rdd2 rdd和rdd2的状态会分别保存
  - 弹性 存储弹性 分布式弹性 容错可以分多个partition存 每个partition有多个副本
  - 分布式
  - 并行计算
- RDD创建
  - spark context
    - ① 在内存中 list（ iterable ）
    - ② 从文件中加载
  - 在创建rdd的时候可以指定partitons的数量，决定了运算的并行度。 一个partition对应一个task。
- 三类算子
  - transformation
    - 返回rdd
    - 延迟执行 只要没调用action类算子 就不会执行 只是记下了执行计划
  - action
    - 获取结果
- spark启动模式： local模式 & standalone（几种模式）

- 广播变量——避免数据的过渡复制。

### Hbase 回顾

- 面向列 列式存储
  - 每一列数据是放到同一个文件中的， 列与列之间存储的位置并不连续
  - 传统数据库：数据是一行一行存的，每一行都是连续的
- 非关系型数据 NoSQL
  - 关系型数据 非关系数据
- 事务
  - 行级别事务 不是事务型数据库
- CAP定理  CP系统
- 行键(RowKey)  只有rowkey有索引
- 列族(ColumnFamily)  k:v数据库 查询性能类似的 k:v 放到同一个ColumnFamily中——联系方式
- 列修饰符(*Column* *Qualifier*)  在ColumnFamily下的 key:value对的key   ColumnFamily:Column *Qualifier*:value——电话：xxx;邮箱：xxx.

### HBase表设计需要注意的问题

- HBase的特点
  - 行级别事务， 如果对跨行事务，跨表事务有很高要求不适合用hbase
  - rowkey有索引
  - ColumnFamily 不宜过多
  - Column Qualifier可以用来存储信息
- Rowkey是HBase表结构设计中很重要的环节, 直接影响到HBase的效率和性能
- HBase的表结构比传统关系型数据库更灵活, 能存储任何二进制数据,无需考虑数据类型
- 利用列标识(Column Qualifier)来存储数据
- 衡量设计好坏的简单标准 是否会全表查询 

HBase shell操作

Happybase 操作hbase

Hbase 需要调整的地方

①删除hadoop 上 /hbase目录

②修改 /root/bigdata/hbase/conf/regionservers

​	只保留hadoop_master

③修改hbase-site.xml

```xml
<configuration>
        <property>
                <name>hbase.rootdir</name>
                <value>hdfs://hadoop-master:9000/hbase</value>
        </property>
        <property>
                <name>hbase.cluster.distributed</name>
                <value>true</value>
        </property>
        <property>
                <name>hbase.zookeeper.property.clientPort</name>
                <value>只保留之前的第一个值</value>
        </property>

        <property>
                <name>hbase.zookeeper.property.dataDir</name>
                <value>保留之前的内容</value>
        </property>
        <property>
                <name>hbase.unsafe.stream.capability.enforce</name>
                <value>false</value>
        </property>
</configuration>

```

④start-hbase.sh 启动hbase
