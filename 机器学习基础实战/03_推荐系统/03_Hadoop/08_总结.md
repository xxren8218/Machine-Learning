### Hadoop 概念

- 分布式的计算框架 **可靠 可扩展**
- **可扩展** ：集群可以上万台，可以提供分布式计算 分布式存储
- **可靠**： high-availability（HA），代码层面，不是硬件
- Hadoop 可以做什么？
  - 数据仓库
    - 数据库一般只保存数据的最新状态，只有极个别的值会保存历史版本
    - 数据仓库 会保存所有的历史版本，只是去记录，很少去做更新和删除
  - PB级别的 存储、处理 分析 统计
    - MySQL、Oracle等关系型数据库，有事务的概念，处理时需要加锁，使得海量数据处理不便。而Hadoop不存在事务的概念。
    - 日志分析
    - 数据挖掘
    - BI



### Hadoop组件

- hadoop common
  - 协调其他组件的通用工具
- HDFS（分布式文件存储系统）
  - 分布式的文件系统
  - 特点 :扩展性&容错性&海量数量存储
  - 数据切成指定大小的数据块进行存储
  - 数据会有冗余（多副本）保存，通过冗余实现容错——一个错了，还有其余副本。
- MapReduce（只能离线计算）
  - 分布式计算框架
  - 数据分布式，需要对分布式存储的数据进行分析和计算，移动数据到一个节点和还是移动计算到每个节点。——MapReaduce:移动计算
  - 特点：扩展性&容错性&海量数量存储
  - 计算分成两个阶段：
    - Map:分
    - Reduce:合
- Hadoop YARN:.(资源调度系统)
  - 之前只有MapReduce，不需资源调度，分配问题。而有了Hive,HBase之后，有处理的优先问题，就需要资源调度系统了
    - 资源管理 作业调度
    - 多个框架会用到HDFS上面的数据，涉及到先后问题，需要框架协调。
    - 之所以叫另一种资源协调者：之前有 Mesos
    - YARN Hadoop2.0版本之后才加进来的。Hadoop1.0是没有的。



### HDFS的设计思路

- 数据冗余——高可用，副本数量也可以指定  3。
- 数据拆分——配置文件中可以指定文件块大小 Block size(默认128MB)
- Namenode：存储元数据：A. 分为 3 份，block id 001 002 003，副本数3 分别存储在datanode1 datanode5 datanode7上
- 架构——最小的分布式：最少三台机器。一个NameNode,两个DataNode，一个挂了，另一个可以正常工作。伪分布式（NM和DN在一个主机上）
  - NameNode
    - 响应客户端的请求
    - 元数据的存储
    - DataNode的管理
  - DataNode
    - 数据的存储
    - 和客户端之间IO的操作
    - 定期向NameNode汇报状况
- NameNode的高可用
  - 3台： 1台活着，另外两个是备份 用 `zookeeper`去管理
  - zookeeper的作用：
    - 保证三台NameNode的数据一致性——同步
    - 主节点选取：若一个死掉，其余补上
- hadoop.apache.org下载hadoop



### YARN架构

- 产生背景：
  - 很多人（框架）访问数据，需要知道他们访问的是否是同一块数据，以及每个每个节点上的负载情况。将这些节点的负载进行均衡调配，产生YARN，2.0之前没有YARN。只有MapReduce。既管算，也管调度。存在一个问题：资源调度和计算耦合到MapReduce上了。但是它的分布式数据没有接口来为各个涌现的计算框架（spark等）使用。YARN出现了。不同计算框架可以共享同一个HDFS集群上的数据，享受整体的资源调度

- 作用：协调多个框架共同访问HDFS集群资源
- 架构：
  - ResourceManager: RM 资源管理器
    - 响应客户端请求
    - 管理NM的状态
    - 响应AM的请求
  - NodeManager: NM 节点管理器
    - 管理自身的资源
    - 启动 Containe，运行 task
    - 响应AM的请求
  - ApplicationMaster: AM
    - 作业解析
    - 向RM请求资源
    - 向NM分发task
  - Container 容器: 封装了CPU、Memory等资源的一个容器,是一个任务运行环境的抽象
  - Client: 客户端提交作业
  - 流程
  - ![](/img/yarn4.png)

1. 客户端发送计算请求给RM

2. RM受到请求以后给一个相对空闲的NM，让他算需要的空间，资源等。

3. NM将这个计算的任务分给AM，AM来做。
4. AM计算完，将所需的内存，资源等告诉RM，RM再告诉AM你需要到哪些空闲的NM上进行。
5. AM收到后，将任务分给空闲的NM。
6. 空闲的NM将任务分给Container进行计算
7. Container计算完成后，结果返回给AM，请求kill进程。
8. AM将结果返回给RM，RM返回给用户。



- 在访问 50070 8088端口失败。可能是防火墙的问题
  - systemctl stop firewalld
  - service iptables stop



### MapReduce

- mapreduce既是一个分布式计算框架，也是一个编程的模型
- 解决的是数据的分布式存储带来的分布式计算问题。
- 把作业通过map阶段下发到每一个数据所在的节点
- 在reduce阶段，汇总map阶段的结果
- 编程时需要实现mapper和reducer接口
- python脚本写map reduce代码的时候，通过hadoop-streaming实现的，最终还会编译成.jar文件去执行。
- hadoop-streaming执行命令

```shell
STREAM_JAR_PATH="/root/bigdata/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.9.1.jar"    # hadoop streaming jar包所在位置
INPUT_FILE_PATH_1="/The_Man_of_Property.txt"  #要进行词频统计的文档在hdfs中的路径
OUTPUT_PATH="/output"                         #MR作业后结果的存放路径

hadoop fs -rm -r -skipTrash $OUTPUT_PATH    #输出路径如果之前存在 先删掉否则会报错

hadoop jar $STREAM_JAR_PATH \   
		-input $INPUT_FILE_PATH_1 \ # 指定输入文件位置
		-output $OUTPUT_PATH \      #指定输出结果位置
		-mapper "python map.py" \   #指定mapper执行的程序
		-reducer "python red.py" \  #指定reduce阶段执行的程序
		-file ./map.py \            #通过-file 把python源文件分发到集群的每一台机器上  
		-file ./red.py
```



### MRjob

- ①写一个类来继承MRjob

- ②重写 mapper 和 reducer 方法

- ③在main方法中，调用MRjob的run() 来开启整个流程
  
  - 实际上通过hadoop进行计算时，还是需要通过streaming,mrjob仅仅是进行一次封装。
  
- MRJob提交作业的方式

  - 本地测试

    ```python
    python mrjob代码 要处理的数据所在位置
    ```

  - 提交到hadoop集群

    ```python
    python word_count.py -r hadoop hdfs:///要统计的文件在hadoop上的位置 -o  hdfs:///输出结果索要保存的位置 
    ```

  - 如果在虚拟环境下运行MRjob可能会报错。（本地python和虚拟机的版本不一样，一个2.7，一个3.x）,需要加参数
  
    - python word_count.py -r hadoop hdfs:///test.txt -o  hdfs:///output  **--python-bin /miniconda2/envs/py365/bin/python** 

- 如果mapreduce有多个步骤 可以通过steps方法指定

```python
实现steps方法用于指定自定义的mapper，comnbiner和reducer方法
    def steps(self):
        return [
            MRStep(mapper=self.mapper,
                   combiner=self.combiner,
                   reducer=self.reducer_sum),
            MRStep(reducer=self.top_n_reducer)
        ]
```



### MapReduce演变和缺点：

- Mapreduce 慢的原因
- 数据处理的时候 频繁的在'`磁盘`和'`内存`上进行数据IO 而不是始终在内存中处理 这些I/0操作导致了速度比较慢
  - buffer in memory：达到80%数据时，将数据锁在内存上，将这部分输出到磁盘上
- MapReduce的架构演变

  - 1.x的时候
    - JobTracker  master 计算集群管理
    - TaskTracker slave  负责具体任务执行的
    - Task Scheduler 作业调度
  - 2.X Yarn出现 作业的调度都交给Yarn处理
    - MapReduce只是进行具体任务执行



### Hadoop发型版本选择

很多版本（Hive1.x，2.x，Hadoop 1.x....）存在兼容问题，如何解决：

- 社区版
  - XXXXXX.apache.org下载
  - 可以下载到最新的版本
  - 如果涉及到的大数据框架比较多， 版本选择不慎可能会有兼容性问题
- CDH版
  - 通过统一CDH版本来避免兼容性问题
    - hadoop-2.6.0-cdh-5.7.0 和 Flume*****-cdh5.7.0
    - 只要CDH版本一致就不会存在兼容性问题
  - 缺点：新版本更新比社区版慢
    - 部分内容没有开源



数据分析/数据挖掘技术栈丰富程度

数据分析  sql pandas numpy excel 算法属于加分项 非大数据场景  10~15K

 大数据相关的分析   sql pandas numy 大数据技术栈 

etl  数据仓库  10~15K

sql pandas numy 大数据技术栈 机器学习算法（原理 应用场景，优化）

数据挖掘 推荐算法 用户画像

15K起

数学/算法的掌握程度

深度学习  nlp

​                 图像

机器学习算法

数学功底比较好

